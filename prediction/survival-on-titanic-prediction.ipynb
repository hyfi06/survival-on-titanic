{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "central-owner",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fabulous-mozambique",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suffering-suffering",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "thick-tissue",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('./data/train.csv')\n",
    "df_test = pd.read_csv('./data/test.csv')\n",
    "df_test_y = pd.read_csv('./data/gender_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "loose-force",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId    0.000000\n",
       "Survived       0.000000\n",
       "Pclass         0.000000\n",
       "Name           0.000000\n",
       "Sex            0.000000\n",
       "Age            0.000000\n",
       "SibSp          0.000000\n",
       "Parch          0.000000\n",
       "Ticket         0.000000\n",
       "Fare           0.000000\n",
       "Cabin          0.771044\n",
       "Embarked       0.002245\n",
       "familysize     0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.isna().sum(axis=0)/len(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "domestic-demographic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId    0.000000\n",
       "Pclass         0.000000\n",
       "Name           0.000000\n",
       "Sex            0.000000\n",
       "Age            0.000000\n",
       "SibSp          0.000000\n",
       "Parch          0.000000\n",
       "Ticket         0.000000\n",
       "Fare           0.000000\n",
       "Cabin          0.782297\n",
       "Embarked       0.000000\n",
       "familysize     0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.isna().sum(axis=0)/len(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "quarterly-electronics",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "expressed-terrorist",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[22.    ,  7.25  ],\n",
       "       [38.    , 71.2833],\n",
       "       [26.    ,  7.925 ],\n",
       "       ...,\n",
       "       [    nan, 23.45  ],\n",
       "       [26.    , 30.    ],\n",
       "       [32.    ,  7.75  ]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[['Age','Fare']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "alive-macro",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_data(df_train, df_test):\n",
    "    # remove NaN\n",
    "    imp = SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "    df_train[['Age','Fare']] = imp.fit_transform(df_train[['Age','Fare']].values)\n",
    "    df_test[['Age','Fare']] = imp.transform(df_test[['Age','Fare']].values)\n",
    "    \n",
    "    # encoder categorical variable\n",
    "    labelEncoder = LabelEncoder()\n",
    "    df_train['Sex'] = labelEncoder.fit_transform(df_train['Sex'])\n",
    "    df_test['Sex'] = labelEncoder.transform(df_test['Sex'])\n",
    "    \n",
    "    # new variables\n",
    "    df_train['familysize'] = df_train['SibSp'] + df_train['Parch']\n",
    "    df_test['familysize'] = df_test['SibSp'] + df_test['Parch']\n",
    "    \n",
    "    X_train = df_train[['Sex','Age','Fare','familysize']].values\n",
    "    X_test = df_test[['Sex','Age','Fare','familysize']].values\n",
    "    y_train = df_train['Survived'].values\n",
    "\n",
    "    return X_train, X_test, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "prerequisite-championship",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train = preprocessing_data(df_train, df_test)\n",
    "y_test = df_test_y['Survived'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "administrative-pregnancy",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "molecular-hungary",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "shaped-bread",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[266   0]\n",
      " [  1 151]]\n",
      "0.9976076555023924\n"
     ]
    }
   ],
   "source": [
    "classifier = RandomForestClassifier(n_estimators=1000, criterion = 'entropy')\n",
    "classifier.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "cm = confusion_matrix(y_test,y_pred)\n",
    "print(cm)\n",
    "print(accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "maritime-habitat",
   "metadata": {},
   "source": [
    "### Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "continued-particular",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_test_y\n",
    "df['Survived'] = y_pred\n",
    "df.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "geological-breakdown",
   "metadata": {},
   "source": [
    "### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "distant-sleeping",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "changing-plastic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model-RandomForestClassifier.pkl']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(classifier, 'model-RandomForestClassifier.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "survival-on-titanic",
   "language": "python",
   "name": "survival-on-titanic"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
